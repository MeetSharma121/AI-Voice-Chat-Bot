# AI Voice Chatbot with LLM & RAG for Healthcare ğŸ’¬ğŸ¤–
<img width="1000" height="200" alt="Screenshot 2025-08-19 at 2 26 52â€¯AM" src="https://github.com/user-attachments/assets/656774ae-abad-4c4b-b8d3-22ef60a7c58f" />




## ğŸ¯ Objective

#### ğŸ’¬ğŸ¤– An AI Voice Assistant that leverages ğŸ§  Large Language Models (LLMs) and ğŸ“š Retrieval-Augmented Generation (RAG) to act as a ğŸ¥ğŸ‘©â€âš•ï¸ virtual medical receptionist. The assistant can â“ answer patient queries, ğŸ“… book appointments, and ğŸ“–âœ… provide guideline-based responses while ensuring ğŸ›¡ï¸ safety, ğŸ¯ accuracy, and ğŸ“œâš–ï¸ compliance with healthcare standards.

## ğŸ—ï¸ Architecture Overview

- **Input Layer**: Speech-to-Text (STT) using Azure Cognitive Services + Text fallback
- **Processing Layer**: LLM + RAG Pipeline with vector database for NHS docs
- **Response Layer**: Text-to-Speech (TTS) + Chat UI
- **Cloud Infrastructure**: Azure Functions + App Services with Docker support

## ğŸ”§ Core Features

- LLM + RAG Querying with NHS knowledge base
- Voice Agent Dialogues with safety compliance
- Multi-channel support (phone + web app)
- Performance monitoring and logging
- GDPR/NHS compliance and data de-identification
## ğŸ“¸ Pictures 

<img width="400" height="500" alt="Screenshot 2025-08-19 at 2 36 26â€¯AM" src="https://github.com/user-attachments/assets/6153fbe1-5db5-4ebb-b502-80baf2429042" />
<img width="400" height="500" alt="Screenshot 2025-08-19 at 2 21 21â€¯AM" src="https://github.com/user-attachments/assets/1c3b22e8-1189-43cb-983a-6eaca7193dde" />
<img width="400" height="500" alt="Screenshot 2025-08-19 at 2 21 28â€¯AM" src="https://github.com/user-attachments/assets/af7b0583-5a4e-497f-a387-ca8018c24438" />
<img width="400" height="500" alt="Screenshot 2025-08-19 at 2 21 46â€¯AM" src="https://github.com/user-attachments/assets/bb34a221-ec2c-4928-bfe1-1266edcc5848" />




## ğŸš€ Quick Start

1. **Install Dependencies**
   ```bash
   pip install -r requirements.txt
   ```

2. **Set Environment Variables**
   ```bash
   cp .env.example .env
   # Fill in your API keys and configuration
   ```

3. **Run the Application**
   ```bash
   python app.py
   ```

4. **Access Web Interface**
   - Open http://localhost:5000 in your browser
   - Use the voice chat interface or text input

## ğŸ“ Project Structure

```
â”œâ”€â”€ app.py                 # Main Flask application
â”œâ”€â”€ config/               # Configuration files
â”œâ”€â”€ core/                 # Core chatbot logic
â”œâ”€â”€ models/               # LLM and embedding models
â”œâ”€â”€ rag/                  # RAG pipeline components
â”œâ”€â”€ voice/                # Speech processing modules
â”œâ”€â”€ web/                  # Web interface components
â”œâ”€â”€ data/                 # Sample NHS data and embeddings
â”œâ”€â”€ tests/                # Test suite
â”œâ”€â”€ docker/               # Docker configuration
â””â”€â”€ docs/                 # Documentation
```

## ğŸ” Environment Variables

- `AZURE_SPEECH_KEY`: Azure Cognitive Services Speech API key
- `AZURE_SPEECH_REGION`: Azure region for speech services
- `OPENAI_API_KEY`: OpenAI API key for LLM
- `PINECONE_API_KEY`: Pinecone vector database API key
- `DATABASE_URL`: Database connection string

## ğŸ§ª Testing

```bash
python -m pytest tests/
```

## ğŸ³ Docker Deployment

```bash
docker build -t healthcare-chatbot .
docker run -p 5000:5000 healthcare-chatbot
```

## ğŸ“š Documentation

See the `docs/` folder for detailed API documentation and deployment guides.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details. 
